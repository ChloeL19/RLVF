{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/chloe/mambaforge/envs/python3.9/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/chloe/mambaforge/envs/python3.9/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /home/chloe/mambaforge/envs/python3.9/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chloe/mambaforge/envs/python3.9/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/chloe/mambaforge/envs/python3.9/lib/libcudart.so'), PosixPath('/home/chloe/mambaforge/envs/python3.9/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, pipeline\n",
    "\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer, set_seed\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import json\n",
    "\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfeedback(v):\n",
    "  '''\n",
    "  Returns the compiler error if one exists. Returns None if everything compiles cleanly.\n",
    "  '''\n",
    "  r = requests.post(\"https://coq.livecode.ch/check\", data = { 'v': v }).json()\n",
    "  if r['status'] == 0:\n",
    "    return None\n",
    "  r = r['log']\n",
    "  return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linenumber(cf):\n",
    "  pattern = r'line (\\d+),'\n",
    "  match = re.search(pattern, cf)  \n",
    "  if match:\n",
    "    line_number = int(match.group(1))\n",
    "  else:\n",
    "    line_number = -1\n",
    "  return line_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_totallines(response):\n",
    "    return len(response.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(line_number, response):\n",
    "    broken = response.split('\\n')\n",
    "    return broken[line_number-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/chloe/.cache/huggingface/datasets/csv/default-abc231268bec9647/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f8fabbcc524fc1958b68cd565b2971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b6ed8b49dc4c6a9cac063ef30f4d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1235001fc50d49d1830abbaf1c4b4eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/chloe/.cache/huggingface/datasets/csv/default-abc231268bec9647/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebc285bc45e44cba04a0987a7de913b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = PPOConfig(\n",
    "    model_name=\"edbeeching/gpt-neo-125M-imdb-lora-adapter-merged\",\n",
    "    learning_rate=1.41e-5,\n",
    "    log_with='wandb',\n",
    "    mini_batch_size=1,# prev: 16\n",
    "    batch_size=1, # prev: 256, but working with super limited samples so will try lower batch size for now\n",
    "    # gradient_accumulation_steps=1, --> apparently this is unrecognized\n",
    ")\n",
    "\n",
    "# We then define the arguments to pass to the sentiment analysis pipeline.\n",
    "# We set `return_all_scores` to True to get the sentiment score for each token.\n",
    "sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": config.mini_batch_size}\n",
    "\n",
    "def build_dataset(config, dataset_name=\"CoqLLMtrain.csv\"):\n",
    "    \"\"\"\n",
    "    Build dataset for training. This builds the dataset from `load_dataset`, one should\n",
    "    customize this function to train the model on its own dataset.\n",
    "    Args:\n",
    "        dataset_name (`str`):\n",
    "            The name of the dataset to be loaded.\n",
    "    Returns:\n",
    "        dataloader (`torch.utils.data.DataLoader`):\n",
    "            The dataloader for the dataset.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    ds = load_dataset(\"csv\", data_files=\"CoqLLMtrain.csv\", split=\"train\")\n",
    "\n",
    "    def concat(sample):\n",
    "      ex = sample['specification'] + \"Test case 1: \" + sample['test_case_1'] + \\\n",
    "      \", test case 2: \" + sample['test_case_2'] + \", test case 3: \" + sample['test_case_3']\n",
    "      return ex\n",
    "\n",
    "      # return sample['specification'] + \"Test case 1: \" + sample['test_case_1'] + \\\n",
    "      # \", test case 2: \" + sample['test_case_2'] + \", test case 3: \" + sample['test_case_3'] + \" Prove some formal properties. Please only write code for the last stand-alone example. *)\"\n",
    "\n",
    "\n",
    "    def tokenize(sample):\n",
    "        sample[\"input_ids\"] = tokenizer.encode(concat(sample))\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds\n",
    "\n",
    "# multi-shot boilerplate\n",
    "multishot = \"(* Stand-alone Example 1: Write a function that doubles a number. Test case 1: double 3 = 6. Prove some formal properties. *) \\nFixpoint double (n: nat): nat := match n with | 0 => 0 | S n => S (S (double n)) end. \\n\\nLemma example_double_3: double 3 = 6.\\nProof. simpl. reflexivity. Qed. \\n\\n Theorem theorem_double_distribute: \\nforall a b, double a + double b = double (a + b).\\n Proof.\\n intros.\\n induction a.\\n - simpl. reflexivity.\\n - simpl. rewrite IHa. reflexivity. \\n Qed. \\n\\n (* Stand-alone Example 2: Write a function that creates a list of n elements. Test case 1: replicate 1 0 = []. Test case 2: replicate 1 2 = [1; 1]. Prove some formal properties. *) \\n Require Import Coq.Lists.List. \\n Open Scope list_scope. \\n Import ListNotations. \\n Fixpoint replicate {X: Type} (x: X) (n: nat): list X := \\n match n with \\n | 0 => []\\n | S n => x :: replicate x n \\n end. \\n Lemma example_replicate_0: replicate 1 0 = []. \\n Proof. simpl. reflexivity. Qed.\\n Lemma example_replicate_2: replicate 1 2 = [1; 1].\\n Proof. simpl. reflexivity. Qed.\\n\\n Theorem replicate_length:\\n\\t forall n, length (replicate 1 n) = n.\\n Proof. \\n intros. \\n induction n.\\n - simpl. reflexivity. \\n - simpl. rewrite IHn. reflexivity.\\n Qed. \\n Theorem replicate_length_any: \\n\\t forall (X: Type) (x: X) n, length (replicate x n) = n. \\n Proof.\\n intros. \\n induction n.\\n - simpl. reflexivity.\\n- simpl. rewrite IHn. reflexivity.\\n Qed.\"\n",
    "\n",
    "# We retrieve the dataloader by calling the `build_dataset` function.\n",
    "dataset = build_dataset(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually I'm loading Llama\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dolly Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import LLMChain, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemText = \"\"\" You are an AI assistant helping users write Coq code in order to implement given function specifications. \n",
    "1. The program you write should only contain Coq code in response to the given function specification. \n",
    "3. Any step-by-step reasoning that is not Coq code should be written as a comment.\n",
    "3. As the user provides compiler feedback, modify and update the program accordingly and keep the variables and the general program structure consistent.\n",
    "4. In addition to implementing the function, give at least 2 properties as theorems with their proofs.\n",
    "\n",
    "The following are examples.\n",
    "\n",
    "Query from user:\n",
    "Write a function that creates a list of n elements. Test case 1: replicate 1 0 = []. Test case 2: replicate 1 2 = [1; 1]. \n",
    "\n",
    "Response from assistant:\n",
    "\\`\\`\\`\n",
    "Require Import Coq.Lists.List. \n",
    " Open Scope list_scope. \n",
    " Import ListNotations. \n",
    " Fixpoint replicate (x: X) (n: nat): list X := \n",
    " match n with \n",
    " | 0 => []\n",
    " | S n => x :: replicate x n \n",
    " end. \n",
    " Lemma example_replicate_0: replicate 1 0 = []. \n",
    " Proof. simpl. reflexivity. Qed.\n",
    " Lemma example_replicate_2: replicate 1 2 = [1; 1].\n",
    " Proof. simpl. reflexivity. Qed.\n",
    "\n",
    " Theorem replicate_length:\n",
    "\t forall n, length (replicate 1 n) = n.\n",
    " Proof. \n",
    " intros. \n",
    " induction n.\n",
    " - simpl. reflexivity. \n",
    " - simpl. rewrite IHn. reflexivity.\n",
    " Qed. \n",
    " Theorem replicate_length_any: \n",
    "\t forall (X: Type) (x: X) n, length (replicate x n) = n. \n",
    " Proof.\n",
    " intros. \n",
    " induction n.\n",
    " - simpl. reflexivity.\n",
    "- simpl. rewrite IHn. reflexivity.\n",
    " Qed.\n",
    "\\`\\`\\`\n",
    "\n",
    "Query from user:\n",
    "Your code produces an error in the line Fixpoint replicate (x: X) (n: nat): list X :=\\n{}Can you please explain what this error means? Let's think step by step. Please rewrite all code if you rewrite any code.\n",
    "File \\\"./ex.v\\\", line 4, characters 24-25:\\nError: The reference X was not found in the current environment.\n",
    "\n",
    "Response from assistant:\n",
    "\\`\\`\\`\n",
    "Require Import Coq.Lists.List. \n",
    " Open Scope list_scope. \n",
    " Import ListNotations. \n",
    " Fixpoint replicate '{X: Type'} (x: X) (n: nat): list X := \n",
    " match n with \n",
    " | 0 => []\n",
    " | S n => x :: replicate x n \n",
    " end. \n",
    " Lemma example_replicate_0: replicate 1 0 = []. \n",
    " Proof. simpl. reflexivity. Qed.\n",
    " Lemma example_replicate_2: replicate 1 2 = [1; 1].\n",
    " Proof. simpl. reflexivity. Qed.\n",
    "\n",
    " Theorem replicate_length:\n",
    "\t forall n, length (replicate 1 n) = n.\n",
    " Proof. \n",
    " intros. \n",
    " induction n.\n",
    " - simpl. reflexivity. \n",
    " - simpl. rewrite IHn. reflexivity.\n",
    " Qed. \n",
    " Theorem replicate_length_any: \n",
    "\t forall (X: Type) (x: X) n, length (replicate x n) = n. \n",
    " Proof.\n",
    " intros. \n",
    " induction n.\n",
    " - simpl. reflexivity.\n",
    "- simpl. rewrite IHn. reflexivity.\n",
    " Qed.\n",
    "\\`\\`\\`\"\"\"\n",
    "\n",
    "messages=[{\"role\": \"system\", \"content\": systemText}]\n",
    "\n",
    "def generate(q):\n",
    "  '''\n",
    "  Generate output from the correct model and clean it from pre- and post- rambles if possible.\n",
    "  ''' \n",
    "  # make this script retry if the connection is rejected for some reason\n",
    "  while True:\n",
    "    try:\n",
    "      messages.append({\"role\": \"user\", \"content\": q})\n",
    "      response = openai.ChatCompletion.create(\n",
    "                    model='gpt-4-0314', \n",
    "                    messages=messages)\n",
    "      response = response.choices[0].message.content\n",
    "      messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "      \n",
    "      # clean the response if possible\n",
    "      c_response = response\n",
    "      try:\n",
    "        match = re.search('```coq(.*?)```', c_response, re.DOTALL)\n",
    "        c_response = match.group(1)\n",
    "      except:\n",
    "        pass\n",
    "      try:\n",
    "        match = re.search('```(.*?)```', c_response, re.DOTALL)\n",
    "        c_response = match.group(1)\n",
    "      except:\n",
    "        pass\n",
    "      return c_response\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "def run_trial(q_core, pid, outfile, verbose=True, ntrials=10):\n",
    "  '''\n",
    "  Runs one trial on one prompt. \n",
    "  - q: function spec with test cases\n",
    "  - pid: the prompt id\n",
    "  '''\n",
    "  q = q_core\n",
    "  if verbose:\n",
    "    print(\"The task: {}\".format(q))\n",
    "\n",
    "  for t in range(ntrials): \n",
    "    # for recording the dataset\n",
    "    out = {\n",
    "            \"prompt_id\": pid,\n",
    "            \"iteration\": t,\n",
    "            \"instruction\": q,\n",
    "            \"output\": None,\n",
    "            \"compiler_feedback\": None,\n",
    "            \"stats\": {\n",
    "                        \"total_lines\" : None,\n",
    "                        \"compiled_lines\": None,\n",
    "                        \"percent_compiled\": None\n",
    "                    }\n",
    "            }\n",
    "\n",
    "    # generate model response\n",
    "    response = generate(q)\n",
    "\n",
    "    # get compiler feedback\n",
    "    cf = cfeedback(response)\n",
    "\n",
    "    if verbose:\n",
    "      print(\"-----Attempt {}---------\".format(t))\n",
    "      print(response)\n",
    "\n",
    "    if cf is not None:\n",
    "      line_number = get_linenumber(cf) - 1\n",
    "      total_lines = get_totallines(response)\n",
    "      percent_compiled = (line_number)/total_lines\n",
    "      linetxt = get_line(line_number, response)\n",
    "\n",
    "      # get the model to reflect on the error\n",
    "      q = \"Your code produces an error in the line {}\\n{}Can you please explain what this error means? Let's think step by step. Please rewrite all code if you rewrite any code.\"\\\n",
    "        .format(linetxt, cf)\n",
    "      if verbose:\n",
    "        print(q)\n",
    "        print(percent_compiled)\n",
    "    else:\n",
    "      total_lines = get_totallines(response)\n",
    "      line_number = total_lines\n",
    "      percent_compiled = 1.0\n",
    "      q = \"The model solved the problem!\"\n",
    "      if verbose:\n",
    "        print(q)\n",
    "        print(percent_compiled)\n",
    "\n",
    "    # append all data to json lines file\n",
    "    out[\"output\"] = response\n",
    "    out[\"compiler_feedback\"] = cf\n",
    "    out[\"stats\"][\"total_lines\"] = total_lines\n",
    "    out[\"stats\"][\"compiled_lines\"] = line_number\n",
    "    out[\"stats\"][\"percent_compiled\"] = percent_compiled\n",
    "\n",
    "    with open(outfile, 'a') as file:\n",
    "      file.write(json.dumps(out) + '\\n')\n",
    "    if verbose:\n",
    "      print(\"recorded in {}\".format(outfile))\n",
    "\n",
    "    # don't continue if model has completely solved problem\n",
    "    if cf is None:\n",
    "      break\n",
    "\n",
    "  return None\n",
    "\n",
    "def main():\n",
    "  pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n",
    "  outfile = \"Dolly_EasyMediumHard01.ndjson\"\n",
    "  # run_trial(q, 0, outfile)\n",
    "  for i in range(0,3):\n",
    "    q = dataset[i]['query'] \n",
    "    run_trial(q, i, outfile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
